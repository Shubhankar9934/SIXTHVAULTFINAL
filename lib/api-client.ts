// RAG Backend API Client
export interface UploadResponse {
  batch_id: string
  count: number
}

export interface QueryResponse {
  answer: string;
  sources?: Array<{
    document: string;
    text: string;
    score: number;
  }>;
}

export interface BackendDocument {
  id: string;
  name: string;
  size: number;
  type: string;
  uploadDate: string;
  status: string;
  progress: number;
  language: string;
  themes: string[];
  keywords: string[];
  demographics: string[];
  summary?: string;
  insights?: string;
  keyInsights?: string[]; // New field from backend
  mainTopics?: string[]; // New field from backend
  sentiment?: string; // New field from backend
  readingLevel?: string; // New field from backend
  content?: string; // New field from backend
  path: string;
}

export interface AvailableModel {
  name: string;
  provider: string;
  displayName: string;
  description?: string;
  isAvailable: boolean;
  isLocal?: boolean;
}

export interface ModelProvider {
  name: string;
  displayName: string;
  isAvailable: boolean;
  models: AvailableModel[];
}

export interface AICuration {
  id: string;
  title: string;
  description: string;
  documentCount: number;
  lastUpdated: string;
  status: 'fresh' | 'stale' | 'updating';
  confidence: number;
  isAutoGenerated: boolean;
  documentIds: string[];
  topicKeywords: string[];
}

export interface CurationSettings {
  autoRefresh: boolean;
  onAdd: 'full' | 'incremental' | 'manual';
  onDelete: 'auto_clean' | 'keep_stale' | 'prompt';
  changeThreshold: number;
  maxCurations: number;
  minDocumentsPerCuration: number;
}

export interface CurationStatus {
  totalCurations: number;
  freshCurations: number;
  staleCurations: number;
  lastGenerated: string | null;
  documentsAnalyzed: number;
}

export interface WebSocketMessage {
  type: 'queued' | 'processing' | 'completed' | 'error' | 
        'bulk_upload_started' | 'tier1_initiated' | 'priority_processing_started' | 
        'rag_available' | 'tier2_initiated' | 'background_processing_started' | 
        'background_file_completed' | 'parallel_progress' | 'task_completed' |
        'priority_processing_error' | 'background_processing_error'
  data: any
  timestamp: string
}

export class RagApiClient {
  private baseUrl: string
  private provider: string
  private hybrid: boolean

  constructor() {
    this.baseUrl = process.env.NEXT_PUBLIC_RAG_API_URL || 'http://localhost:8000'
    this.provider = process.env.NEXT_PUBLIC_RAG_PROVIDER || 'openai'
    this.hybrid = process.env.NEXT_PUBLIC_RAG_HYBRID === 'true'
  }

  private getAuthHeaders(): HeadersInit {
    // Get token from cookie
    const token = document.cookie.split('; ')
      .find(row => row.startsWith('auth-token='))
      ?.split('=')[1]

    return {
      'Authorization': token ? `Bearer ${token}` : '',
      'Cache-Control': 'no-cache', // Prevent caching of sensitive data
      'Pragma': 'no-cache'
    }
  }

  /**
   * Upload files to RAG backend - Enhanced with Bulk Processing Support
   */
  async uploadFiles(files: File[], useBulkProcessing: boolean = false): Promise<UploadResponse> {
    const formData = new FormData()
    
    files.forEach(file => {
      formData.append('files', file)
    })

    // Use bulk endpoint if multiple files or explicitly requested
    const endpoint = (files.length > 1 || useBulkProcessing) ? '/upload/bulk' : '/upload'
    const url = `${this.baseUrl}${endpoint}`

    // Enhanced logging for debugging
    console.log('=== API CLIENT UPLOAD DEBUG (ENHANCED BULK PROCESSING) ===')
    console.log('Provider: ollama (hardcoded)')
    console.log('Model: llama3.2:latest (hardcoded)')
    console.log('Processing Strategy:', files.length > 1 ? 'Two-Tier Bulk Processing' : 'Standard Processing')
    console.log('Endpoint:', endpoint)
    console.log('Final URL:', url)
    console.log('Files being uploaded:', files.map(f => f.name))
    console.log('=== END API CLIENT DEBUG ===')

    try {
      const response = await fetch(url, {
        method: 'POST',
        headers: this.getAuthHeaders(),
        body: formData
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(errorData.detail || `Upload failed: ${response.status}`)
      }

      return await response.json()
    } catch (error) {
      console.error('Upload error:', error)
      throw error
    }
  }

  /**
   * Query documents using RAG - Ollama Only
   */
  async queryDocuments(
    question: string, 
    options: {
      hybrid?: boolean
      maxContext?: boolean
      documentIds?: string[]
      provider?: string
      model?: string
    } = {}
  ): Promise<QueryResponse> {
    const { hybrid = this.hybrid, maxContext = false, documentIds, provider = 'ollama', model } = options
    
    const url = new URL(`${this.baseUrl}/query`)
    url.searchParams.set('hybrid', hybrid.toString())
    url.searchParams.set('max_context', maxContext.toString())

    console.log('=== API CLIENT QUERY DEBUG (MULTI-PROVIDER) ===')
    console.log('Provider:', provider)
    console.log('Model:', model)
    console.log('Hybrid:', hybrid)
    console.log('Max Context:', maxContext)
    console.log('Document IDs:', documentIds)
    console.log('Final URL:', url.toString())
    console.log('=== END API CLIENT DEBUG ===')

    try {
      const response = await fetch(url.toString(), {
        method: 'POST',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({ 
          question,
          document_ids: documentIds,
          provider: provider,
          model: model
        })
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(errorData.detail || `Query failed: ${response.status}`)
      }

      return await response.json()
    } catch (error) {
      console.error('Query error:', error)
      throw error
    }
  }

  /**
   * Connect to WebSocket for progress updates with enhanced reliability
   */
  connectWebSocket(batchId: string): WebSocket {
    // Get token from cookie
    const token = document.cookie.split('; ')
      .find(row => row.startsWith('auth-token='))
      ?.split('=')[1]

    const wsUrl = `${this.baseUrl.replace('http', 'ws')}/ws/${batchId}${token ? `?token=${token}` : ''}`
    const ws = new WebSocket(wsUrl)

    ws.onopen = () => {
      console.log(`WebSocket connected for batch: ${batchId}`)
    }

    ws.onerror = (error) => {
      console.error('WebSocket error:', error)
    }

    ws.onclose = (event) => {
      console.log(`WebSocket closed for batch: ${batchId}`, event.code, event.reason)
    }

    return ws
  }

  /**
   * Pre-establish WebSocket connection before upload
   */
  async preEstablishWebSocket(batchId: string): Promise<WebSocket> {
    return new Promise((resolve, reject) => {
      const ws = this.connectWebSocket(batchId)
      
      const timeout = setTimeout(() => {
        ws.close()
        reject(new Error('WebSocket connection timeout'))
      }, 10000) // 10 second timeout
      
      ws.onopen = () => {
        clearTimeout(timeout)
        console.log(`WebSocket pre-established for batch: ${batchId}`)
        resolve(ws)
      }
      
      ws.onerror = (error) => {
        clearTimeout(timeout)
        console.error('WebSocket pre-establishment failed:', error)
        reject(error)
      }
    })
  }

  /**
   * Enterprise-grade WebSocket with intelligent reconnection and message handling
   */
  createReliableWebSocket(batchId: string, onMessage: (data: any) => void): {
    ws: WebSocket | null,
    connect: () => Promise<void>,
    disconnect: () => void,
    isConnected: () => boolean,
    sendMessage: (message: any) => Promise<boolean>,
    getConnectionHealth: () => Promise<any>
  } {
    let ws: WebSocket | null = null
    let reconnectAttempts = 0
    const maxReconnectAttempts = 8
    let isManuallyDisconnected = false
    let reconnectTimeout: NodeJS.Timeout | null = null
    let heartbeatInterval: NodeJS.Timeout | null = null
    let connectionStartTime = 0
    let lastMessageTime = 0
    let messageQueue: any[] = []

    const connect = async (): Promise<void> => {
      return new Promise((resolve, reject) => {
        try {
          if (ws && ws.readyState === WebSocket.OPEN) {
            resolve()
            return
          }

          connectionStartTime = Date.now()
          ws = this.connectWebSocket(batchId)
          
          const timeout = setTimeout(() => {
            if (ws) ws.close()
            reject(new Error('Enterprise WebSocket connection timeout'))
          }, 15000) // Increased timeout for enterprise reliability

          ws.onopen = () => {
            clearTimeout(timeout)
            reconnectAttempts = 0
            lastMessageTime = Date.now()
            
            console.log(`Enterprise WebSocket connected for batch: ${batchId}`)
            
            // Send client ready signal
            sendMessage({ type: 'client_ready', timestamp: Date.now() })
            
            // Start heartbeat monitoring
            startHeartbeat()
            
            // Flush any queued messages
            flushMessageQueue()
            
            resolve()
          }

          ws.onmessage = (event) => {
            try {
              lastMessageTime = Date.now()
              const data = JSON.parse(event.data)
              
              // Handle special message types
              if (data.type === 'heartbeat') {
                // Respond to server heartbeat
                sendMessage({ type: 'pong', timestamp: Date.now() })
                return
              }
              
              if (data.type === 'connection_status') {
                console.log('Connection status update:', data.data)
                // Don't pass connection status to main handler unless it's critical
                if (data.data?.status === 'established' || data.data?.status === 'error') {
                  onMessage(data)
                }
                return
              }
              
              if (data.type === 'flush_start') {
                console.log('Server starting message flush:', data.data)
                return
              }
              
              if (data.type === 'flush_complete') {
                console.log('Server completed message flush:', data.data)
                return
              }
              
              // Pass all other messages to the handler
              onMessage(data)
              
            } catch (error) {
              console.error('Failed to parse WebSocket message:', error)
            }
          }

          ws.onclose = (event) => {
            clearTimeout(timeout)
            stopHeartbeat()
            
            console.log(`Enterprise WebSocket closed for batch: ${batchId}`, event.code, event.reason)
            
            // Attempt intelligent reconnection
            if (!isManuallyDisconnected && reconnectAttempts < maxReconnectAttempts) {
              reconnectAttempts++
              
              // Exponential backoff with jitter
              const baseDelay = Math.min(1000 * Math.pow(2, reconnectAttempts), 30000)
              const jitter = Math.random() * 1000
              const delay = baseDelay + jitter
              
              console.log(`Attempting enterprise WebSocket reconnection ${reconnectAttempts}/${maxReconnectAttempts} in ${delay.toFixed(0)}ms`)
              
              reconnectTimeout = setTimeout(() => {
                connect().catch((error) => {
                  console.error('Reconnection failed:', error)
                  if (reconnectAttempts >= maxReconnectAttempts) {
                    console.error('Max reconnection attempts reached for batch:', batchId)
                    onMessage({
                      type: 'connection_failed',
                      data: {
                        message: 'Failed to establish reliable connection after multiple attempts',
                        batch_id: batchId,
                        attempts: reconnectAttempts
                      }
                    })
                  }
                })
              }, delay)
            }
          }

          ws.onerror = (error) => {
            clearTimeout(timeout)
            console.error('Enterprise WebSocket error:', error)
            reject(error)
          }

        } catch (error) {
          reject(error)
        }
      })
    }

    const sendMessage = async (message: any): Promise<boolean> => {
      if (ws && ws.readyState === WebSocket.OPEN) {
        try {
          ws.send(JSON.stringify(message))
          return true
        } catch (error) {
          console.error('Failed to send WebSocket message:', error)
          messageQueue.push(message)
          return false
        }
      } else {
        // Queue message for later delivery
        messageQueue.push(message)
        return false
      }
    }

    const flushMessageQueue = () => {
      if (messageQueue.length > 0 && ws && ws.readyState === WebSocket.OPEN) {
        console.log(`Flushing ${messageQueue.length} queued client messages`)
        const messages = [...messageQueue]
        messageQueue = []
        
        messages.forEach(message => {
          try {
            ws!.send(JSON.stringify(message))
          } catch (error) {
            console.error('Failed to flush queued message:', error)
            messageQueue.push(message) // Re-queue failed message
          }
        })
      }
    }

    const startHeartbeat = () => {
      stopHeartbeat()
      heartbeatInterval = setInterval(() => {
        if (ws && ws.readyState === WebSocket.OPEN) {
          sendMessage({ type: 'ping', timestamp: Date.now() })
          
          // Check for stale connection
          const timeSinceLastMessage = Date.now() - lastMessageTime
          if (timeSinceLastMessage > 60000) { // 1 minute without any message
            console.warn('WebSocket connection appears stale, requesting status')
            sendMessage({ type: 'request_status' })
          }
        }
      }, 20000) // Send ping every 20 seconds
    }

    const stopHeartbeat = () => {
      if (heartbeatInterval) {
        clearInterval(heartbeatInterval)
        heartbeatInterval = null
      }
    }

    const getConnectionHealth = async (): Promise<any> => {
      if (ws && ws.readyState === WebSocket.OPEN) {
        await sendMessage({ type: 'request_health' })
        return {
          connected: true,
          uptime: Date.now() - connectionStartTime,
          lastMessage: Date.now() - lastMessageTime,
          reconnectAttempts,
          queuedMessages: messageQueue.length
        }
      }
      return {
        connected: false,
        uptime: 0,
        lastMessage: -1,
        reconnectAttempts,
        queuedMessages: messageQueue.length
      }
    }

    const disconnect = () => {
      isManuallyDisconnected = true
      stopHeartbeat()
      
      if (reconnectTimeout) {
        clearTimeout(reconnectTimeout)
        reconnectTimeout = null
      }
      
      if (ws) {
        ws.close(1000, 'Manual disconnect')
        ws = null
      }
      
      messageQueue = []
      console.log(`Enterprise WebSocket manually disconnected for batch: ${batchId}`)
    }

    const isConnected = () => {
      return ws !== null && ws.readyState === WebSocket.OPEN
    }

    return { 
      ws, 
      connect, 
      disconnect, 
      isConnected, 
      sendMessage, 
      getConnectionHealth 
    }
  }

  /**
   * Get user documents from backend with enhanced retry logic for ngrok
   */
  async getUserDocuments(): Promise<BackendDocument[]> {
    const maxRetries = 3
    let lastError: Error | null = null

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`API Client: Fetching documents (attempt ${attempt}/${maxRetries}) from:`, `${this.baseUrl}/documents`)
        
        const response = await fetch(`${this.baseUrl}/documents`, {
          headers: {
            ...this.getAuthHeaders(),
            'Content-Type': 'application/json',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'ngrok-skip-browser-warning': 'true'
          }
        })

        console.log(`API Client: Response status: ${response.status} (attempt ${attempt})`)

        if (!response.ok) {
          if (response.status === 401) {
            throw new Error('Authentication failed - please log in again')
          }
          if (response.status === 404) {
            console.log('API Client: Documents endpoint not found, returning empty array')
            return []
          }
          throw new Error(`HTTP ${response.status}: ${response.statusText}`)
        }

        // Check if response has content
        const contentType = response.headers.get('content-type')
        if (!contentType || !contentType.includes('application/json')) {
          console.warn('API Client: Response is not JSON, returning empty array')
          return []
        }

        const text = await response.text()
        if (!text.trim()) {
          console.warn('API Client: Empty response body, returning empty array')
          return []
        }

        try {
          const data = JSON.parse(text)
          console.log(`API Client: Successfully parsed ${data.length || 0} documents (attempt ${attempt})`)
          return Array.isArray(data) ? data : []
        } catch (parseError) {
          console.error('API Client: JSON parse error:', parseError)
          console.error('API Client: Response text length:', text.length)
          console.error('API Client: Response text preview:', text.substring(0, 200) + '...')
          
          // Check if this is the specific "Unterminated string" error
          if (parseError instanceof SyntaxError && parseError.message.includes('Unterminated string')) {
            console.error('API Client: Detected unterminated string error - likely large response truncation')
            
            // Try to salvage partial JSON by finding the last complete object
            try {
              const lastCompleteIndex = text.lastIndexOf('"}]')
              if (lastCompleteIndex > 0) {
                const truncatedText = text.substring(0, lastCompleteIndex + 3)
                console.log('API Client: Attempting to parse truncated response...')
                const salvaged = JSON.parse(truncatedText)
                console.log(`API Client: Successfully salvaged ${salvaged.length || 0} documents from truncated response`)
                return Array.isArray(salvaged) ? salvaged : []
              }
            } catch (salvageError) {
              console.error('API Client: Failed to salvage truncated response:', salvageError)
            }
          }
          
          return []
        }

      } catch (error) {
        lastError = error as Error
        console.error(`API Client: Attempt ${attempt} failed:`, error)
        
        // Don't retry authentication errors
        if (error instanceof Error && error.message.includes('Authentication failed')) {
          throw error
        }
        
        if (attempt < maxRetries) {
          const delay = Math.pow(2, attempt) * 1000 // Exponential backoff: 2s, 4s, 8s
          console.log(`API Client: Retrying in ${delay}ms...`)
          await new Promise(resolve => setTimeout(resolve, delay))
        }
      }
    }

    console.error('API Client: All retry attempts failed:', lastError)
    throw lastError || new Error('Failed to fetch documents after multiple attempts')
  }

  /**
   * Delete a document and all associated data
   */
  async deleteDocument(documentId: string): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseUrl}/documents/${documentId}`, {
        method: 'DELETE',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json'
        }
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(errorData.detail || `Delete failed: ${response.status}`)
      }

      const result = await response.json()
      console.log('Document deletion result:', result)
      return true
    } catch (error) {
      console.error('Delete document error:', error)
      throw error
    }
  }

  /**
   * Health check
   */
  async healthCheck(): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseUrl}/health`, {
        method: 'GET'
      })
      return response.ok
    } catch (error) {
      console.error('Health check failed:', error)
      return false
    }
  }

  /**
   * Get available providers
   */
  getAvailableProviders(): string[] {
    return ['openai', 'groq', 'anthropic', 'local']
  }

  /**
   * Get available models - Enhanced Multi-Provider Support with Better Error Handling
   */
  async getAvailableModels(): Promise<ModelProvider[]> {
    console.log('🔍 API Client: Starting getAvailableModels() - Enhanced Multi-Provider Mode')
    console.log('🌐 API Client: Base URL:', this.baseUrl)
    
    try {
      // Enhanced request with better headers and error handling
      console.log('🚀 API Client: Attempting to fetch all providers from:', `${this.baseUrl}/ollama/all-providers`)
      
      const response = await fetch(`${this.baseUrl}/ollama/all-providers`, {
        method: 'GET',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'Accept': 'application/json',
          'Cache-Control': 'no-cache',
          'ngrok-skip-browser-warning': 'true'
        },
        mode: 'cors',
        credentials: 'include'
      })
      
      console.log('📊 API Client: All providers response status:', response.status)
      console.log('📋 API Client: Response headers:', Object.fromEntries(response.headers.entries()))
      
      if (response.ok) {
        const responseText = await response.text()
        console.log('📝 API Client: Raw response text length:', responseText.length)
        
        if (!responseText.trim()) {
          console.warn('⚠️ API Client: Empty response body from all-providers endpoint')
          throw new Error('Empty response from server')
        }
        
        let data
        try {
          data = JSON.parse(responseText)
          console.log('✅ API Client: All providers data parsed successfully:', data)
        } catch (parseError) {
          console.error('❌ API Client: JSON parse error:', parseError)
          console.error('📄 API Client: Response text preview:', responseText.substring(0, 500))
          throw new Error(`Invalid JSON response: ${parseError}`)
        }
        
        if (data.providers && Array.isArray(data.providers) && data.providers.length > 0) {
          const providers: ModelProvider[] = data.providers.map((provider: any) => ({
            name: provider.name,
            displayName: provider.displayName || provider.name.charAt(0).toUpperCase() + provider.name.slice(1),
            isAvailable: provider.isAvailable !== false, // Default to true if not specified
            models: (provider.models || []).map((model: any) => ({
              name: model.name,
              provider: provider.name,
              displayName: model.displayName || model.name,
              description: model.description || 'AI model',
              isAvailable: model.isAvailable !== false,
              isLocal: model.isLocal || false
            }))
          }))
          
          console.log('🎉 API Client: Successfully loaded', providers.length, 'providers with models:')
          providers.forEach(p => console.log(`   - ${p.displayName}: ${p.models.length} models (available: ${p.isAvailable})`))
          return providers
        } else {
          console.warn('⚠️ API Client: No valid providers in response:', data)
        }
      } else {
        const errorText = await response.text().catch(() => 'Unable to read error response')
        console.error('❌ API Client: All providers endpoint failed:', response.status, response.statusText)
        console.error('📄 API Client: Error response:', errorText)
        
        if (response.status === 401) {
          throw new Error('Authentication failed - please log in again')
        } else if (response.status === 404) {
          console.log('📍 API Client: All providers endpoint not found, using fallback strategy')
        } else {
          throw new Error(`HTTP ${response.status}: ${errorText}`)
        }
      }
      
      console.log('🔄 API Client: All providers endpoint failed, falling back to individual provider fetching')
    } catch (error) {
      console.error('❌ API Client: Failed to fetch all providers:', error)
      console.log('🔄 API Client: Proceeding with fallback strategy')
    }
    
    // Enhanced fallback strategy - try to build providers manually
    const providers: ModelProvider[] = []

    // Try Ollama first (most likely to work)
    try {
      console.log('🔍 API Client: Attempting to fetch Ollama models from:', `${this.baseUrl}/ollama/models`)
      
      const ollamaResponse = await fetch(`${this.baseUrl}/ollama/models`, {
        method: 'GET',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'Accept': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        },
        mode: 'cors',
        credentials: 'include'
      })
      
      console.log('📊 API Client: Ollama response status:', ollamaResponse.status)
      
      if (ollamaResponse.ok) {
        const ollamaText = await ollamaResponse.text()
        
        if (ollamaText.trim()) {
          const ollamaData = JSON.parse(ollamaText)
          console.log('✅ API Client: Ollama data received:', ollamaData)
          
          if (ollamaData.models && Array.isArray(ollamaData.models) && ollamaData.models.length > 0) {
            const ollamaModels: AvailableModel[] = ollamaData.models.map((model: any) => ({
              name: model.name,
              provider: 'ollama',
              displayName: model.name.replace(':', ' ').replace(/\b\w/g, (l: string) => l.toUpperCase()),
              description: model.recommended_for || `Local AI model (${(model.size / (1024**3)).toFixed(1)}GB)`,
              isAvailable: true,
              isLocal: true
            }))

            providers.push({
              name: 'ollama',
              displayName: 'Ollama (Local AI)',
              isAvailable: true,
              models: ollamaModels
            })
            
            console.log('🎉 API Client: Successfully added Ollama provider with', ollamaModels.length, 'models')
          }
        }
      } else {
        console.warn('⚠️ API Client: Ollama endpoint returned:', ollamaResponse.status)
      }
    } catch (error) {
      console.warn('⚠️ API Client: Failed to fetch Ollama models:', error)
    }

    // Only add default Ollama configuration if the endpoint didn't explicitly exclude it
    // (If Ollama is disabled, the backend won't include it in the response)
    if (!providers.find(p => p.name === 'ollama')) {
      console.log('➕ API Client: Adding default Ollama provider (assuming enabled)')
      providers.push({
        name: 'ollama',
        displayName: 'Ollama (Local AI)',
        isAvailable: true,
        models: [
          {
            name: 'llama3.2:latest',
            provider: 'ollama',
            displayName: 'Llama 3.2 Latest',
            description: 'Latest Llama 3.2 model - High performance',
            isAvailable: true,
            isLocal: true
          },
          {
            name: 'llama3.2:3b',
            provider: 'ollama',
            displayName: 'Llama 3.2 3B',
            description: 'Fast 3B parameter model',
            isAvailable: true,
            isLocal: true
          },
          {
            name: 'phi3:mini',
            provider: 'ollama',
            displayName: 'Phi-3 Mini',
            description: 'Microsoft\'s efficient small model',
            isAvailable: true,
            isLocal: true
          }
        ]
      })
    }

    // Add other providers based on available API keys
    console.log('🔑 API Client: Adding cloud providers based on configuration...')

    // OpenAI Provider
    providers.push({
      name: 'openai',
      displayName: 'OpenAI',
      isAvailable: true, // We'll assume it's available if configured
      models: [
        {
          name: 'gpt-4o-mini',
          provider: 'openai',
          displayName: 'GPT-4o Mini',
          description: 'Fast and cost-effective GPT-4 model',
          isAvailable: true,
          isLocal: false
        },
        {
          name: 'gpt-3.5-turbo',
          provider: 'openai',
          displayName: 'GPT-3.5 Turbo',
          description: 'Fast and reliable ChatGPT model',
          isAvailable: true,
          isLocal: false
        },
        {
          name: 'gpt-4',
          provider: 'openai',
          displayName: 'GPT-4',
          description: 'Most capable OpenAI model',
          isAvailable: true,
          isLocal: false
        }
      ]
    })

    // Groq Provider
    providers.push({
      name: 'groq',
      displayName: 'Groq',
      isAvailable: true,
      models: [
        {
          name: 'llama3-8b-8192',
          provider: 'groq',
          displayName: 'Llama 3 8B',
          description: 'Ultra-fast Llama 3 with 8K context',
          isAvailable: true,
          isLocal: false
        },
        {
          name: 'mixtral-8x7b-32768',
          provider: 'groq',
          displayName: 'Mixtral 8x7B',
          description: 'High-performance mixture of experts',
          isAvailable: true,
          isLocal: false
        }
      ]
    })

    // Gemini Provider
    providers.push({
      name: 'gemini',
      displayName: 'Google Gemini',
      isAvailable: true,
      models: [
        {
          name: 'gemini-1.5-flash',
          provider: 'gemini',
          displayName: 'Gemini 1.5 Flash',
          description: 'Fast and efficient Gemini model',
          isAvailable: true,
          isLocal: false
        },
        {
          name: 'gemini-1.5-pro',
          provider: 'gemini',
          displayName: 'Gemini 1.5 Pro',
          description: 'Most capable Gemini model',
          isAvailable: true,
          isLocal: false
        }
      ]
    })

    // DeepSeek Provider
    providers.push({
      name: 'deepseek',
      displayName: 'DeepSeek',
      isAvailable: true,
      models: [
        {
          name: 'deepseek-chat',
          provider: 'deepseek',
          displayName: 'DeepSeek Chat',
          description: 'Cost-effective high-performance chat model',
          isAvailable: true,
          isLocal: false
        },
        {
          name: 'deepseek-coder',
          provider: 'deepseek',
          displayName: 'DeepSeek Coder',
          description: 'Specialized coding model',
          isAvailable: true,
          isLocal: false
        }
      ]
    })

    console.log('🎉 API Client: Final providers summary:')
    console.log(`   Total providers: ${providers.length}`)
    providers.forEach(p => {
      console.log(`   - ${p.displayName}: ${p.models.length} models (${p.isAvailable ? 'Available' : 'Unavailable'})`)
    })
    
    return providers
  }

  /**
   * Get models for a specific provider
   */
  async getProviderModels(providerName: string): Promise<AvailableModel[]> {
    const providers = await this.getAvailableModels()
    const provider = providers.find(p => p.name === providerName)
    return provider?.models || []
  }

  /**
   * AI Curation API Methods
   */

  /**
   * Get user's AI curations
   */
  async getAICurations(): Promise<AICuration[]> {
    try {
      console.log('API Client: Fetching AI curations from:', `${this.baseUrl}/curations`)
      
      const response = await fetch(`${this.baseUrl}/curations`, {
        method: 'GET',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        }
      })

      if (!response.ok) {
        if (response.status === 401) {
          throw new Error('Authentication failed - please log in again')
        }
        if (response.status === 404) {
          console.log('API Client: Curations endpoint not found, returning empty array')
          return []
        }
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const data = await response.json()
      console.log('API Client: Successfully fetched', data.length || 0, 'AI curations')
      return Array.isArray(data) ? data : []
    } catch (error) {
      console.error('API Client: Failed to fetch AI curations:', error)
      return []
    }
  }

  /**
   * Generate/regenerate AI curations
   */
  async generateAICurations(options: {
    provider?: string
    model?: string
    forceRegenerate?: boolean
  } = {}): Promise<{ success: boolean; message: string; curations?: AICuration[] }> {
    try {
      console.log('API Client: Generating AI curations with options:', options)
      
      const response = await fetch(`${this.baseUrl}/curations/generate`, {
        method: 'POST',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        },
        body: JSON.stringify({
          provider: options.provider,
          model: options.model,
          force_regenerate: options.forceRegenerate || false
        })
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(errorData.detail || `Generation failed: ${response.status}`)
      }

      const result = await response.json()
      console.log('API Client: AI curation generation result:', result)
      return result
    } catch (error) {
      console.error('API Client: Failed to generate AI curations:', error)
      return {
        success: false,
        message: error instanceof Error ? error.message : 'Unknown error occurred'
      }
    }
  }

  /**
   * Get AI curation settings
   */
  async getCurationSettings(): Promise<CurationSettings> {
    try {
      const response = await fetch(`${this.baseUrl}/curations/settings`, {
        method: 'GET',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        }
      })

      if (!response.ok) {
        if (response.status === 404) {
          // Return default settings if not found
          return {
            autoRefresh: true,
            onAdd: 'incremental',
            onDelete: 'auto_clean',
            changeThreshold: 15,
            maxCurations: 10,
            minDocumentsPerCuration: 2
          }
        }
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      return await response.json()
    } catch (error) {
      console.error('API Client: Failed to fetch curation settings:', error)
      // Return default settings on error
      return {
        autoRefresh: true,
        onAdd: 'incremental',
        onDelete: 'auto_clean',
        changeThreshold: 15,
        maxCurations: 10,
        minDocumentsPerCuration: 2
      }
    }
  }

  /**
   * Update AI curation settings
   */
  async updateCurationSettings(settings: Partial<CurationSettings>): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseUrl}/curations/settings`, {
        method: 'PUT',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        },
        body: JSON.stringify(settings)
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(errorData.detail || `Update failed: ${response.status}`)
      }

      console.log('API Client: Successfully updated curation settings')
      return true
    } catch (error) {
      console.error('API Client: Failed to update curation settings:', error)
      return false
    }
  }

  /**
   * Get AI curation system status
   */
  async getCurationStatus(): Promise<CurationStatus> {
    try {
      const response = await fetch(`${this.baseUrl}/curations/status`, {
        method: 'GET',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        }
      })

      if (!response.ok) {
        if (response.status === 404) {
          // Return default status if not found
          return {
            totalCurations: 0,
            freshCurations: 0,
            staleCurations: 0,
            lastGenerated: null,
            documentsAnalyzed: 0
          }
        }
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      return await response.json()
    } catch (error) {
      console.error('API Client: Failed to fetch curation status:', error)
      // Return default status on error
      return {
        totalCurations: 0,
        freshCurations: 0,
        staleCurations: 0,
        lastGenerated: null,
        documentsAnalyzed: 0
      }
    }
  }

  /**
   * Refresh a specific AI curation
   */
  async refreshCuration(curationId: string, options: {
    provider?: string
    model?: string
  } = {}): Promise<{ success: boolean; message: string; curation?: AICuration }> {
    try {
      const response = await fetch(`${this.baseUrl}/curations/${curationId}/refresh`, {
        method: 'POST',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        },
        body: JSON.stringify({
          provider: options.provider,
          model: options.model
        })
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(errorData.detail || `Refresh failed: ${response.status}`)
      }

      const result = await response.json()
      console.log('API Client: Curation refresh result:', result)
      return result
    } catch (error) {
      console.error('API Client: Failed to refresh curation:', error)
      return {
        success: false,
        message: error instanceof Error ? error.message : 'Unknown error occurred'
      }
    }
  }

  /**
   * Create a custom AI curation with user-defined topic and keywords
   */
  async createCustomCuration(options: {
    title: string
    description?: string
    keywords: string[]
    provider: string
    model: string
  }): Promise<{ success: boolean; message: string; curation?: AICuration }> {
    try {
      console.log('API Client: Creating custom curation:', options.title)
      
      const response = await fetch(`${this.baseUrl}/curations/custom`, {
        method: 'POST',
        headers: {
          ...this.getAuthHeaders(),
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        },
        body: JSON.stringify({
          title: options.title,
          description: options.description,
          keywords: options.keywords,
          provider: options.provider,
          model: options.model
        })
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(errorData.detail || `Custom curation creation failed: ${response.status}`)
      }

      const result = await response.json()
      console.log('API Client: Custom curation creation result:', result)
      return {
        success: true,
        message: 'Custom curation created successfully',
        curation: result
      }
    } catch (error) {
      console.error('API Client: Failed to create custom curation:', error)
      return {
        success: false,
        message: error instanceof Error ? error.message : 'Unknown error occurred'
      }
    }
  }

  /**
   * Update configuration
   */
  updateConfig(config: {
    provider?: string
    hybrid?: boolean
    baseUrl?: string
  }) {
    if (config.provider) this.provider = config.provider
    if (config.hybrid !== undefined) this.hybrid = config.hybrid
    if (config.baseUrl) this.baseUrl = config.baseUrl
  }
}

// Export singleton instance
export const ragApiClient = new RagApiClient()
